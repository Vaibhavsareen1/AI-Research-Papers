Paper Name: AI Chains: Transparent and Controllable human AI interaction by chaining large language model prompts
By: Tongshuang Wu, Michael Terry and Carrie J. Cai
Paper Link: https://arxiv.org/pdf/2110.01691
Paper Submission Date: 17th of March 2022
============================================================================================================================================
Why this paper?
============================================================================================================================================
AI agents will need to perform reasoning in order to interact with humans and with each other. The idea that the agents will be able to
understand a task in a single turn conversation is wrong. There are steps takens towards incorporating datasets containing Chain of Thought
(CoT) datasets and we do see an increase in their performance but the models have not been able to extrapolate it for complex tasks which
are not a part of the training datasets. In order for the AI agents to interact without human intervention we need to understand how we can
generalize splitting of a single complicated task into multiple simple tasks so that these tasks can be layered in an orderly manner and
solve the complicated tasks. This paper helps me understand a methodology that can help break down a complex task into simpler subtasks whose
output can later be merged together to produce the final output. This approach can later be refined so that the AI agents perform it on their
own.  
============================================================================================================================================
Content - 1. Introduction
============================================================================================================================================
Large Language Models (LLM) have introduced new possibilities for human-AI collboration, these models are pretrained on billions/trillions
of input tokens which helps them generalize on a large set of natural language (now including computer vision and audio) tasks. These
successes have been enabled by their abilitiy to adapt to desired task purely using prompts or natural language descriptions of the tasks.

Many real world tasks can be quite complex and may present challenges for LLMs to solve from a single model run (perform the entire task
and provide the correct output in a single turn conversation). LLMs may fail to capture the subtleties of many tasks that involve multiple
objectives to be fulfilled simultaneously. While LLMs can perform each task separately with a high degree of success in most of the cases
it is still difficult to perform complex tasks which have multiple objectives in a single model run.

It is a difficult task to produce a single prompt which can help the language model perform complex tasks in one go and also be consistent
in its output generation where a human has confidence on the model's output.

The authors of the paper introduce the notion of chaining of multiple LLM prompts together to perform a task for better performance.
Chaining takes advantage of LLMs unique ability to handle a variety of independent tasks. In a 'chain' the problem is broken down into
multiple smaller tasks (sub-tasks), where each sub-task is assigned its own natural language prompts. Output of one subtask is the input for
the other this goes on till the end of the process. In this way chaining enables users to run the same model on multiple sub tasks thereby,
granting each sub-task a higher likelihood of success.
============================================================================================================================================
Content - 2. Related Work
============================================================================================================================================
Not Needed
============================================================================================================================================
Content - 3. Chaining LLMs
============================================================================================================================================
Authors define 'Chaining' as -
"The process of breaking up complex tasks into smaller steps, where each step can be completed by an independent run of an LLM, and where
the output of one or more steps is used as input for the next."

3.1 LLM challenges and primitive operations
According to authors there are three challenges that LLMs face:
3.1.1 LLMs lack multi-step reasoning capabilities.
    LLMs are designed to grasp the form of language rather than the meaning, they are able to perform multi-step/hop problems but not 
    consistent on a real world use cases.
3.1.2 LLMs suffer from exposure bias
    Most of the LLMs are autoregressive models which means the prediction of tokens generated by the models are dependent on the tokens
    predicted before them, thus LLMs are less likely to perform well when generating long bodies of text. This leads to exposure bias as the 
    LLMs due to this process produce redundant content.
3.1.3 LLMs are sensitive to input prompts
    They tend to favor certain prompt formats, paraphrases or even certain information in the input. Prompt format that are unnatural 
    relative to the typical text distribution tend to be less efficient.

3.2 Designing Operations for LLM Chaining
    An LLM chain consists of multiple steps. Authors define each step as an 'LLM operation' which takes in input data and produces output
    data which the authors call 'Data Layers'. Each step (LLM Operation and its Data Layer) is accomplished through a natural language prompt
    These prompts are usually task dependent but they can have some task-agnostic properties. These tasks agnostic properties help to produce
    consistent outputs. According to the authors there are three requirements to satisfy for 'chaining of prompts'.
3.2.1 LLM operation need to invoke the desired functionalities.
    To date the most common patterns for prompting are either zero-shot or few-shot prompts. Zero-shot prompts directly describe what ought to
    happen in a task, whereas few-shot prompts show LLMs what pattern to follow by feeding it examples of the desired input and output data. be
    zero-shot or few-shot prompts each prompt should have prefixes which demarcate the structure and which helps to re-emphasize the desired
    intent.
3.2.2 LLM operation should be able to tak custom data layers as inputs and outputs.
    An LLM operation should be able to handle any custom data layers. This it is neccessary to create prompt templates to support wide range or
    scenarios, with placeholders for input and output data.
3.2.3 Operationns should be able to handle parsing of the expected input/output data types.
    Different data layers may take on different data types. Thought needs to be put into how outputs from the data layers will be taken into
    considerations.
============================================================================================================================================
Content - 4. Interactive user interface
============================================================================================================================================
Not Needed
============================================================================================================================================
Content - 5. User Study
============================================================================================================================================
Not Needed
============================================================================================================================================
Content - 6: Case Studies
============================================================================================================================================
Not Needed
============================================================================================================================================
Content - 7: Discussion and Future Direction
============================================================================================================================================
Not Needed
============================================================================================================================================
Content - 8: Conclusion
============================================================================================================================================
Not Needed