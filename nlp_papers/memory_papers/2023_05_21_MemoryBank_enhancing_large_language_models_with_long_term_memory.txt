============================================================================================================================================
Information about the paper
============================================================================================================================================
Paper Name: MemoryBank: Enhancing Large Language models with long term memory
By: Wanjun Zhong, Lianghon Guo, Qiqi Gao, He Ye and Yanlin Wang
Paper Link: https://arxiv.org/pdf/2305.10250
Paper Submission Date: 21st of May 2023
============================================================================================================================================
Why this paper?
============================================================================================================================================
To understand how to add external memory to my AI agent at inference time the memory bank paper provides a good technique which can be 
implemented without fine tuning LLM model
============================================================================================================================================
Content - 1. Introduction
============================================================================================================================================
Powerful AI systems with the help of Large Language Models (LLMs) have demonstrated a remarkable capability to understand and generate human
like responses. Despite the remarkable capabilities of LLMs a key limitation is their lack of long term memory, particularly noticeable in 
scenarios requiring sustained interactions like personal companionship, psychological counselling, and secretarial tasks.

Long-term memory in AI is vital to maintain contextual understanding, ensuring meaningful interactions and understanding user's behaviour
overtime. The absence of long term memory in LLMs hinders their performance and user experience. Therefore it is essential to develop AI 
systems with improved memory capabilities for a more seamless and personalized interactions.

The authors of the paper MemoryBank introduces a novel mechanism designed to provide LLMs with the ability to retain long term memory and draw
user portraits. MemoryBank enables LLMs to recall historical interactions, continually evolve their understanding of context, and adapt to a 
user's personality based on past interactions, thereby enhancing their performance in long term interaction scenarios.

The paper has been inspired by the Ebbinghaus Forgetting Curve Theory, a well established psychological principle that describes how to
strength of memory decreases over time. MemoryBank further incorporates a dynamic memory mechanism closely mirroring human cognitive process.
This mechanism empowers the AI to remember, selectively forget and strengthen memories based on time elapsed, offering more natural and 
engaging user experience.

Specifically MemoryBank is built on a memory storage with memory retrieval and updating mechanism and ability to summarize past events and user
personality.
============================================================================================================================================
Content - 2. MemoryBank: A novel memory mechanism tailored for LLMs
============================================================================================================================================
MemoryBank's movel mechanism is a unified mechanism structured around three center pillars
2.0.1 Memory storage
    - Storage serving as a the primary data repository
2.0.2 Memory Retriever
    - Retriever which retrieves context-specific memory recollection
2.0.3 Memory Updator
    - Updator which updates memory based on Ebbinghaus principle pertaining to memory retention and forgetting

2.1 Memory Storage: THe warehouse of MemoryBank:
    Memory storage the warehouse of MemoryBank is a robust data repository holding an array of Information. It stores conversational records
    (in-depth memory storage), summaries of past event (hierarchial event summary) and evolving assessments of user personalities
    (dynamic personality understanding). This therefore creates a dynamic multi layered memory landscape.

2.1.1 In-Depth Memory Storage:
    - The storage system records the AI-User (can be used to store AI - AI interactions) by recording multi-turn conversations in a detailed
    chronological fashion.
    - Each piece of dialogue is stored with timestamps, creating an ordered narrative of past interactions. This detailed record not only aids
    in precise memory retrieval but also facilitates the memory updating process afterwards, offering a detailed index of conversational 
    history.

2.1.2 Hierarchial Event Summary:
    - It processes and distills conversations into a high level summary of daily events. The verbose dialogues are condensed into a concise
    daily event summary.
    - Daily summaries are also further synthesized into a global summary.
    - This process results in a hierarchial memory structure, providing a bird's eye view of the past interactions and significant events.

2.1.3 Dynamic Personality Understanding:
    - MemoryBank focuses on user personality understanding as well
    - It continously assesses and updates these understandings with the long term interactions and creates daily personality insights.
    - These daily insights are further aggregated to form a global understanding of the user's personality.

These 3 components of the memory storage lead to a multi tiered approach that results in an AI that learns, adapts and tailors its responses
to the unique traits of each other.

2.2 Memory Retrieval:
    - The memory retrieval mechanism operates akin to knowledge retrieval task. Authors adopt retrieval similar to that of used in DPR retrievers.
    - Every turn of conversations and event summaries is considered as a memory piece m, which is pre encoded into a contextual representation h_m
    using an encoder model.
    - The entire memory storage M is pre-encoded into M = {h_m0, h_m1, ..., h_mM} where each h_m is a vector representations of a memory piece
    which are stored in vector database.
    - Current context of conversation c is also encoded using the same encoder into h_c, which serves as the query to search M for the most relevant
    memory.

2.3 Memory updating mechanism:
    - With memory storage and memory retrieval mechanism the memorization capabilities of LLMs can be greatly enhanced but for more anthropopathic
    memory behaviour (human like memory behaviour) memory updating is needed. Forgetting less important memory pieces that are a long time ago and
    not have been recalled much can make the AI companion more natural.
    - The paper has a simple forgetting mechanism which has been inspired from Ebbinghaus Forgetting Curve Theory and follows the following 
    principle rules:
        - Rate of Forgetting: Memory retention decrease over time. Information is lost rapidly after learning unless it is consciously reviewed.
        - Time and Memory Decay: The curve is steep at the beginning indicating that s significant amount of learned information is forgetten
        within the first few hours or days after learning. after this initial period the rate of meomry loss slow down.
        - Spacing Effect: Relearning information is easier than learning it for the first time. Regularly revisiting and repeating the learned 
        material can reset the forgetting curve, making it less steep and thereby improving memory retention.

The key components to be designed for a working MemoryBank:
1.  Storage which takes care of dialogues in a chronological order based on timestamp of when the dialogues took place, the storage should store
    both dialogues (user and AI's or both AI's used in the conversation.)
2.  Summaries on a daily level of verbose dialogues of that days
3.  Summaries on a global level by summarizing all of the daily level summaries
4.  User's personality summary on a daily basis
5.  User's personality which updates if the user's personality changes based on daily summaries
6.  RAG setup to store memory, summaries and personality into the vector database
============================================================================================================================================
Content - 3. SiliconFriend: An AI Chatbot Companion Powered by MemoryBank
============================================================================================================================================
3.1 Parameter-efficient tuning with psychological dialogue data:
Not needed

3.2 Integration with MemoryBank:
integration of any AI model with MemoryBank is an important step to provide the model with the ability to store, retrieve past interactions
and understand user portraits.

What authors have done with their SiliconFriend AI model is that they have is the dialogues between SiliconFriend and user are logged and
updated in the memory storage. The memory updating mechanism operates using principles inspired by the Ebbinghaus Forgetting Curve Theory.

During real-time conversation, the user's conversation serves as the query for memory retrieval. Upon memory retrieval, a series of information
is organized into the conversation prompt including:
    - relevant memory
    - global user portraits
    - global event summary
============================================================================================================================================
Content - 4. Experiments
============================================================================================================================================
4.1 Qualitative Analysis
Not needed

4.2 Quantitative Analysis
Not needed
============================================================================================================================================
Content - 4. Experiments
============================================================================================================================================
Not needed
============================================================================================================================================
Content - 4. Experiments
============================================================================================================================================
Not needed